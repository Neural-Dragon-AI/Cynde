{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we focused on integrating Polars DataFrames with scikit-learn's pipeline and preprocessing functionality to create a streamlined and efficient machine learning workflow. The main objective was to leverage the power of Polars for data manipulation and the flexibility of scikit-learn for model training and evaluation.\n",
    "\n",
    "Here's a summary of what we accomplished:\n",
    "\n",
    "1. Data Preparation:\n",
    "   - We defined a `convert_utf8_to_enum` function to convert categorical columns in a Polars DataFrame from UTF-8 to the Enum data type based on a specified threshold.\n",
    "   - We created Pydantic classes (`Feature`, `NumericalFeature`, `EmbeddingFeature`, `CategoricalFeature`, `FeatureSet`, and `InputConfig`) to define and validate the feature sets used in the machine learning pipeline.\n",
    "   - We generated simulated data using the `generate_simulated_data` function to demonstrate the workflow.\n",
    "\n",
    "2. Pipeline Creation:\n",
    "   - We defined a `create_pipeline` function that takes an `InputConfig` instance and creates a scikit-learn `Pipeline` object.\n",
    "   - The pipeline consists of a `ColumnTransformer` for preprocessing numerical and categorical features, followed by a `LinearSVC` classifier.\n",
    "   - For numerical features, we used `StandardScaler` to standardize the data.\n",
    "   - For categorical features, we used `\"passthrough\"` to pass the physical representation of the Enum columns directly through the pipeline, avoiding the need for `OneHotEncoder`.\n",
    "   - We set the output of the pipeline to \"polars\" using `pipeline.set_output(transform=\"polars\")` to ensure that the pipeline returns a Polars DataFrame.\n",
    "\n",
    "3. Model Training and Evaluation:\n",
    "   - We simulated cross-validation by filtering the DataFrame based on a \"fold\" column to obtain the training, validation, and test sets.\n",
    "   - We fit the pipeline on the training data using `pipeline.fit()`.\n",
    "   - We evaluated the model's performance on the validation and test data using the `evaluate_model` function, which calculates the accuracy using scikit-learn's `accuracy_score`.\n",
    "\n",
    "4. Integration with Polars:\n",
    "   - Throughout the example, we used Polars DataFrames for data manipulation and preprocessing.\n",
    "   - We converted the categorical columns to their physical representation using `pl.col(col).to_physical()` to ensure compatibility with the pipeline.\n",
    "   - We used Polars' `filter` and `drop` methods to select the appropriate subsets of data for training, validation, and testing.\n",
    "\n",
    "In our next working session, we will focus on the following tasks:\n",
    "\n",
    "1. Refactoring the Cynde-related methods to integrate the new approaches developed in this example.\n",
    "2. Introducing equivalent models for defining the model configurations, replacing the current dictionary-based approach.\n",
    "3. Cleaning and generalizing all the cross-validation methods under a common framework to improve code organization and reusability.\n",
    "\n",
    "By building upon the foundation established in this example and incorporating the planned enhancements, we aim to create a more robust, efficient, and user-friendly machine learning framework within the Cynde project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier,HistGradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from typing import List, Optional\n",
    "from pydantic import BaseModel, ValidationInfo, model_validator\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from typing import Optional, Union, Dict, Literal\n",
    "from pydantic import BaseModel, Field, model_validator\n",
    "import polars as pl\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler, RobustScaler, PowerTransformer, QuantileTransformer, Normalizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "class ScalerType(str, Enum):\n",
    "    STANDARD_SCALER = \"StandardScaler\"\n",
    "    MIN_MAX_SCALER = \"MinMaxScaler\"\n",
    "    MAX_ABS_SCALER = \"MaxAbsScaler\"\n",
    "    ROBUST_SCALER = \"RobustScaler\"\n",
    "    POWER_TRANSFORMER = \"PowerTransformer\"\n",
    "    QUANTILE_TRANSFORMER = \"QuantileTransformer\"\n",
    "    NORMALIZER = \"Normalizer\"\n",
    "\n",
    "class Feature(BaseModel):\n",
    "    column_name: str\n",
    "    name: str\n",
    "    description: Optional[str] = None\n",
    "\n",
    "    @model_validator(mode='before')\n",
    "    def validate_column_name(cls, values):\n",
    "        column_name = values.get(\"column_name\")\n",
    "        context = values.get(\"context\")\n",
    "        if context is not None and isinstance(context, pl.DataFrame):\n",
    "            if column_name not in context.columns:\n",
    "                raise ValueError(f\"Column '{column_name}' not found in the DataFrame.\")\n",
    "        return values\n",
    "\n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n",
    "        extra = \"allow\"\n",
    "\n",
    "class NumericalFeature(Feature):\n",
    "    scaler_type: ScalerType = Field(ScalerType.STANDARD_SCALER, description=\"The type of scaler to apply to the numerical feature.\")\n",
    "\n",
    "    def get_scaler(self):\n",
    "        scaler_map = {\n",
    "            ScalerType.STANDARD_SCALER: StandardScaler(),\n",
    "            ScalerType.MIN_MAX_SCALER: MinMaxScaler(),\n",
    "            ScalerType.MAX_ABS_SCALER: MaxAbsScaler(),\n",
    "            ScalerType.ROBUST_SCALER: RobustScaler(),\n",
    "            ScalerType.POWER_TRANSFORMER: PowerTransformer(),\n",
    "            ScalerType.QUANTILE_TRANSFORMER: QuantileTransformer(),\n",
    "            ScalerType.NORMALIZER: Normalizer(),\n",
    "        }\n",
    "        return scaler_map[self.scaler_type]\n",
    "\n",
    "    @model_validator(mode='before')\n",
    "    def validate_numerical_column(cls, values):\n",
    "        column_name = values.get(\"column_name\")\n",
    "        context = values.get(\"context\")\n",
    "        if context is not None and isinstance(context, pl.DataFrame):\n",
    "            if column_name not in context.columns:\n",
    "                raise ValueError(f\"Column '{column_name}' not found in the DataFrame.\")\n",
    "            if context[column_name].dtype not in [\n",
    "                pl.Boolean,\n",
    "                pl.Int8,\n",
    "                pl.Int16,\n",
    "                pl.Int32,\n",
    "                pl.Int64,\n",
    "                pl.UInt8,\n",
    "                pl.UInt16,\n",
    "                pl.UInt32,\n",
    "                pl.UInt64,\n",
    "                pl.Float32,\n",
    "                pl.Float64,\n",
    "                pl.Decimal,\n",
    "            ]:\n",
    "                raise ValueError(\n",
    "                    f\"Column '{column_name}' must be of a numeric type (Boolean, Integer, Unsigned Integer, Float, or Decimal).\"\n",
    "                )\n",
    "        return values\n",
    "\n",
    "class EmbeddingFeature(NumericalFeature):\n",
    "    @model_validator(mode='before')\n",
    "    def validate_embedding_column(cls, values):\n",
    "        column_name = values.get(\"column_name\")\n",
    "        context = values.get(\"context\")\n",
    "        if context is not None and isinstance(context, pl.DataFrame):\n",
    "            if column_name not in context.columns:\n",
    "                raise ValueError(f\"Column '{column_name}' not found in the DataFrame.\")\n",
    "            if context[column_name].dtype not in [pl.List(pl.Float32), pl.List(pl.Float64)]:\n",
    "                raise ValueError(f\"Column '{column_name}' must be of type pl.List(pl.Float32) or pl.List(pl.Float64).\")\n",
    "        return values\n",
    "\n",
    "class CategoricalFeature(Feature):\n",
    "    one_hot_encoding: bool = Field(True, description=\"Whether to apply one-hot encoding to the categorical feature.\")\n",
    "\n",
    "    @model_validator(mode='before')\n",
    "    def validate_categorical_column(cls, values):\n",
    "        column_name = values.get(\"column_name\")\n",
    "        context = values.get(\"context\")\n",
    "        if context is not None and isinstance(context, pl.DataFrame):\n",
    "            if column_name not in context.columns:\n",
    "                raise ValueError(f\"Column '{column_name}' not found in the DataFrame.\")\n",
    "            if context[column_name].dtype not in [\n",
    "                pl.Utf8,\n",
    "                pl.Categorical,\n",
    "                pl.Enum,\n",
    "                pl.Int8,\n",
    "                pl.Int16,\n",
    "                pl.Int32,\n",
    "                pl.Int64,\n",
    "                pl.UInt8,\n",
    "                pl.UInt16,\n",
    "                pl.UInt32,\n",
    "                pl.UInt64,\n",
    "            ]:\n",
    "                raise ValueError(\n",
    "                    f\"Column '{column_name}' must be of type pl.Utf8, pl.Categorical, pl.Enum, or an integer type.\"\n",
    "                )\n",
    "        return values\n",
    "\n",
    "class FeatureSet(BaseModel):\n",
    "    numerical: List[NumericalFeature] = []\n",
    "    embeddings: List[EmbeddingFeature] = []\n",
    "    categorical: List[CategoricalFeature] = []\n",
    "\n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n",
    "        extra = \"allow\"\n",
    "\n",
    "class InputConfig(BaseModel):\n",
    "    feature_sets: List[FeatureSet]\n",
    "\n",
    "    def validate_with_dataframe(self, df: pl.DataFrame):\n",
    "        for feature_set in self.feature_sets:\n",
    "            for feature_type in [\"numerical\", \"embeddings\", \"categorical\"]:\n",
    "                for feature in getattr(feature_set, feature_type):\n",
    "                    feature.model_validate({\"context\": df, **feature.dict()})\n",
    "\n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n",
    "        extra = \"allow\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_simulated_data(n_samples: int, n_classes: int) -> pl.DataFrame:\n",
    "    class_0 = np.random.multivariate_normal(mean=[30, 50000], cov=[[100, 0], [0, 1000000]], size=n_samples // 2)\n",
    "    class_1 = np.random.multivariate_normal(mean=[50, 80000], cov=[[100, 0], [0, 1000000]], size=n_samples // 2)\n",
    "    data = {\n",
    "        \"age\": np.concatenate((class_0[:, 0], class_1[:, 0])),\n",
    "        \"income\": np.concatenate((class_0[:, 1], class_1[:, 1])),\n",
    "        \"gender\": np.random.choice([\"Male\", \"Female\"], size=n_samples),\n",
    "        \"education\": np.random.choice([\"Bachelor's\", \"Master's\", \"PhD\"], size=n_samples),\n",
    "        \"target\": np.concatenate((np.zeros(n_samples // 2), np.ones(n_samples // 2))),\n",
    "        \"fold\": np.random.choice([0, 1, 2], size=n_samples),\n",
    "    }\n",
    "    return pl.DataFrame(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from typing import Optional, Union, Dict, Literal, Any, List, Tuple\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class ClassifierName(str, Enum):\n",
    "    LOGISTIC_REGRESSION = \"LogisticRegression\"\n",
    "    RANDOM_FOREST = \"RandomForestClassifier\"\n",
    "    HIST_GRADIENT_BOOSTING = \"HistGradientBoostingClassifier\"\n",
    "\n",
    "class BaseClassifierConfig(BaseModel):\n",
    "    classifier_name: ClassifierName\n",
    "\n",
    "class LogisticRegressionConfig(BaseClassifierConfig):\n",
    "    classifier_name: Literal[ClassifierName.LOGISTIC_REGRESSION] = ClassifierName.LOGISTIC_REGRESSION\n",
    "    penalty: str = Field(\"l2\", description=\"Specify the norm of the penalty.\")\n",
    "    dual: bool = Field(False, description=\"Dual or primal formulation.\")\n",
    "    tol: float = Field(1e-4, description=\"Tolerance for stopping criteria.\")\n",
    "    C: float = Field(1.0, description=\"Inverse of regularization strength.\")\n",
    "    fit_intercept: bool = Field(True, description=\"Specifies if a constant should be added to the decision function.\")\n",
    "    intercept_scaling: float = Field(1, description=\"Scaling factor for the constant.\")\n",
    "    class_weight: Optional[Union[str, Dict[Any, float]]] = Field(None, description=\"Weights associated with classes.\")\n",
    "    random_state: Optional[int] = Field(None, description=\"Seed for random number generation.\")\n",
    "    solver: str = Field(\"lbfgs\", description=\"Algorithm to use in the optimization problem.\")\n",
    "    max_iter: int = Field(100, description=\"Maximum number of iterations.\")\n",
    "    multi_class: str = Field(\"auto\", description=\"Approach for handling multi-class targets.\")\n",
    "    verbose: int = Field(0, description=\"Verbosity level.\")\n",
    "    warm_start: bool = Field(False, description=\"Reuse the solution of the previous call to fit.\")\n",
    "    n_jobs: Optional[int] = Field(None, description=\"Number of CPU cores to use.\")\n",
    "    l1_ratio: Optional[float] = Field(None, description=\"Elastic-Net mixing parameter.\")\n",
    "\n",
    "class RandomForestClassifierConfig(BaseClassifierConfig):\n",
    "    classifier_name: Literal[ClassifierName.RANDOM_FOREST] = ClassifierName.RANDOM_FOREST\n",
    "    n_estimators: int = Field(100, description=\"The number of trees in the forest.\")\n",
    "    criterion: str = Field(\"gini\", description=\"The function to measure the quality of a split.\")\n",
    "    max_depth: Optional[int] = Field(None, description=\"The maximum depth of the tree.\")\n",
    "    min_samples_split: Union[int, float] = Field(2, description=\"The minimum number of samples required to split an internal node.\")\n",
    "    min_samples_leaf: Union[int, float] = Field(1, description=\"The minimum number of samples required to be at a leaf node.\")\n",
    "    min_weight_fraction_leaf: float = Field(0.0, description=\"The minimum weighted fraction of the sum total of weights required to be at a leaf node.\")\n",
    "    max_features: Union[str, int, float] = Field(\"sqrt\", description=\"The number of features to consider when looking for the best split.\")\n",
    "    max_leaf_nodes: Optional[int] = Field(None, description=\"Grow trees with max_leaf_nodes in best-first fashion.\")\n",
    "    min_impurity_decrease: float = Field(0.0, description=\"A node will be split if this split induces a decrease of the impurity greater than or equal to this value.\")\n",
    "    bootstrap: bool = Field(True, description=\"Whether bootstrap samples are used when building trees.\")\n",
    "    oob_score: bool = Field(False, description=\"Whether to use out-of-bag samples to estimate the generalization score.\")\n",
    "    n_jobs: Optional[int] = Field(None, description=\"Number of CPU cores to use.\")\n",
    "    random_state: Optional[int] = Field(None, description=\"Seed for random number generation.\")\n",
    "    verbose: int = Field(0, description=\"Verbosity level.\")\n",
    "    warm_start: bool = Field(False, description=\"Reuse the solution of the previous call to fit and add more estimators to the ensemble.\")\n",
    "    class_weight: Optional[Union[str, Dict[Any, float]]] = Field(None, description=\"Weights associated with classes.\")\n",
    "    ccp_alpha: float = Field(0.0, description=\"Complexity parameter used for Minimal Cost-Complexity Pruning.\")\n",
    "    max_samples: Optional[Union[int, float]] = Field(None, description=\"If bootstrap is True, the number of samples to draw from X to train each base estimator.\")\n",
    "    monotonic_cst: Optional[Dict[str, int]] = Field(None, description=\"Monotonic constraint to enforce on each feature.\")\n",
    "\n",
    "class HistGradientBoostingClassifierConfig(BaseClassifierConfig):\n",
    "    classifier_name: Literal[ClassifierName.HIST_GRADIENT_BOOSTING] = ClassifierName.HIST_GRADIENT_BOOSTING\n",
    "    loss: str = Field(\"log_loss\", description=\"The loss function to use in the boosting process.\")\n",
    "    learning_rate: float = Field(0.1, description=\"The learning rate, also known as shrinkage.\")\n",
    "    max_iter: int = Field(100, description=\"The maximum number of iterations of the boosting process.\")\n",
    "    max_leaf_nodes: int = Field(31, description=\"The maximum number of leaves for each tree.\")\n",
    "    max_depth: Optional[int] = Field(None, description=\"The maximum depth of each tree.\")\n",
    "    min_samples_leaf: int = Field(20, description=\"The minimum number of samples per leaf.\")\n",
    "    l2_regularization: float = Field(0.0, description=\"The L2 regularization parameter.\")\n",
    "    max_features: Union[str, int, float] = Field(1.0, description=\"Proportion of randomly chosen features in each and every node split.\")\n",
    "    max_bins: int = Field(255, description=\"The maximum number of bins to use for non-missing values.\")\n",
    "    categorical_features: Optional[Union[str, List[int], List[bool]]] = Field(\"warn\", description=\"Indicates the categorical features.\")\n",
    "    monotonic_cst: Optional[Dict[str, int]] = Field(None, description=\"Monotonic constraint to enforce on each feature.\")\n",
    "    interaction_cst: Optional[Union[str, List[Tuple[int, ...]]]] = Field(None, description=\"Specify interaction constraints, the sets of features which can interact with each other in child node splits.\")\n",
    "    warm_start: bool = Field(False, description=\"Reuse the solution of the previous call to fit and add more estimators to the ensemble.\")\n",
    "    early_stopping: Union[str, bool] = Field(\"auto\", description=\"Whether to use early stopping to terminate training when validation score is not improving.\")\n",
    "    scoring: Optional[str] = Field(\"loss\", description=\"Scoring parameter to use for early stopping.\")\n",
    "    validation_fraction: float = Field(0.1, description=\"Proportion of training data to set aside as validation data for early stopping.\")\n",
    "    n_iter_no_change: int = Field(10, description=\"Used to determine when to stop if validation score is not improving.\")\n",
    "    tol: float = Field(1e-7, description=\"The absolute tolerance to use when comparing scores.\")\n",
    "    verbose: int = Field(0, description=\"Verbosity level.\")\n",
    "    random_state: Optional[int] = Field(None, description=\"Seed for random number generation.\")\n",
    "    class_weight: Optional[Union[str, Dict[Any, float]]] = Field(None, description=\"Weights associated with classes.\")\n",
    "\n",
    "class ClassifierConfig(BaseModel):\n",
    "    classifier: Union[LogisticRegressionConfig, RandomForestClassifierConfig, HistGradientBoostingClassifierConfig]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating LogisticRegressionConfig\n",
      "Validation accuracy: 1.0\n",
      "Test accuracy: 1.0\n",
      "\n",
      "Evaluating RandomForestClassifierConfig\n",
      "Validation accuracy: 1.0\n",
      "Test accuracy: 1.0\n",
      "\n",
      "Evaluating HistGradientBoostingClassifierConfig\n",
      "Validation accuracy: 1.0\n",
      "Test accuracy: 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tommaso\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:110: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "found 0 physical cores < 1\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"c:\\Users\\Tommaso\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 217, in _count_physical_cores\n",
      "    raise ValueError(\n"
     ]
    }
   ],
   "source": [
    "def convert_utf8_to_enum(df: pl.DataFrame, threshold: float = 0.2) -> pl.DataFrame:\n",
    "    if not 0 < threshold < 1:\n",
    "        raise ValueError(\"Threshold must be between 0 and 1 (exclusive).\")\n",
    "\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == pl.Utf8 and len(df[column]) > 0:\n",
    "            unique_values = df[column].unique()\n",
    "            unique_ratio = len(unique_values) / len(df[column])\n",
    "\n",
    "            if unique_ratio <= threshold:\n",
    "                enum_dtype = pl.Enum(unique_values.to_list())\n",
    "                df = df.with_columns(df[column].cast(enum_dtype))\n",
    "            else:\n",
    "                print(f\"Column '{column}' has a high ratio of unique values ({unique_ratio:.2f}). Skipping conversion to Enum.\")\n",
    "        elif df[column].dtype == pl.Utf8 and len(df[column]) == 0:\n",
    "            print(f\"Column '{column}' is empty. Skipping conversion to Enum.\")\n",
    "\n",
    "    return df\n",
    "def evaluate_model(pipeline: Pipeline, X, y):\n",
    "    predictions = pipeline.predict(X)\n",
    "    accuracy = accuracy_score(y, predictions)\n",
    "    return accuracy\n",
    "\n",
    "def convert_enum_to_physical(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    df_physical = df.with_columns(\n",
    "        [pl.col(col).to_physical() for col in df.columns if df[col].dtype == pl.Enum]\n",
    "    )\n",
    "    return df_physical\n",
    "\n",
    "def create_pipeline(df: pl.DataFrame, input_config: InputConfig, classifier_config: ClassifierConfig) -> Pipeline:\n",
    "    transformers = []\n",
    "    for feature_set in input_config.feature_sets:\n",
    "        numerical_features = [feature.column_name for feature in feature_set.numerical]\n",
    "        if numerical_features:\n",
    "            scaler = feature_set.numerical[0].get_scaler()  # Assuming all numerical features use the same scaler\n",
    "            transformers.append((\"numerical\", scaler, numerical_features))\n",
    "\n",
    "        categorical_features = [feature.column_name for feature in feature_set.categorical]\n",
    "        if categorical_features:\n",
    "            for feature in feature_set.categorical:\n",
    "                if feature.one_hot_encoding:\n",
    "                    if df[feature.column_name].dtype == pl.Categorical:\n",
    "                        categories = [df[feature.column_name].unique().to_list()]\n",
    "                    elif df[feature.column_name].dtype == pl.Enum:\n",
    "                        categories = [df[feature.column_name].dtype.categories]\n",
    "                    else:\n",
    "                        raise ValueError(f\"Column '{feature.column_name}' must be of type pl.Categorical or pl.Enum for one-hot encoding.\")\n",
    "                    one_hot_encoder = OneHotEncoder(categories=categories, handle_unknown='error', sparse_output=False)\n",
    "                    transformers.append((f\"categorical_{feature.column_name}\", one_hot_encoder, [feature.column_name]))\n",
    "                else:\n",
    "                    if df[feature.column_name].dtype not in [pl.Float32, pl.Float64]:\n",
    "                        raise ValueError(f\"Column '{feature.column_name}' must be of type pl.Float32 or pl.Float64 for physical representation.\")\n",
    "                    transformers.append((f\"categorical_{feature.column_name}\", \"passthrough\", [feature.column_name]))\n",
    "\n",
    "    preprocessor = ColumnTransformer(transformers)\n",
    "\n",
    "    # Create the classifier based on the classifier configuration\n",
    "    if isinstance(classifier_config.classifier, LogisticRegressionConfig):\n",
    "        classifier = LogisticRegression(**classifier_config.classifier.dict(exclude={\"classifier_name\"}))\n",
    "    elif isinstance(classifier_config.classifier, RandomForestClassifierConfig):\n",
    "        classifier = RandomForestClassifier(**classifier_config.classifier.dict(exclude={\"classifier_name\"}))\n",
    "    elif isinstance(classifier_config.classifier, HistGradientBoostingClassifierConfig):\n",
    "        classifier = HistGradientBoostingClassifier(**classifier_config.classifier.dict(exclude={\"classifier_name\"}))\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported classifier: {type(classifier_config.classifier)}\")\n",
    "\n",
    "    pipeline = Pipeline([(\"preprocessor\", preprocessor), (\"classifier\", classifier)])\n",
    "    pipeline.set_output(transform=\"polars\")\n",
    "    return pipeline\n",
    "\n",
    "# Example usage\n",
    "n_samples = 1000\n",
    "n_classes = 2\n",
    "df = generate_simulated_data(n_samples, n_classes)\n",
    "# Convert categorical columns to Enum\n",
    "df_enum = convert_utf8_to_enum(df, threshold=0.8)\n",
    "df_physical = df_enum\n",
    "\n",
    "# Declare feature sets using Pydantic classes\n",
    "numerical_features = [\n",
    "    NumericalFeature(column_name=\"age\", name=\"Age\"),\n",
    "    NumericalFeature(column_name=\"income\", name=\"Income\"),\n",
    "]\n",
    "categorical_features = [\n",
    "    CategoricalFeature(column_name=\"gender\", name=\"Gender\"),\n",
    "    CategoricalFeature(column_name=\"education\", name=\"Education\"),\n",
    "]\n",
    "feature_set = FeatureSet(\n",
    "    numerical=numerical_features,\n",
    "    categorical=categorical_features,\n",
    ")\n",
    "input_config = InputConfig(feature_sets=[feature_set])\n",
    "\n",
    "# Declare classifier configurations\n",
    "classifier_configs = [\n",
    "    ClassifierConfig(\n",
    "        classifier=LogisticRegressionConfig(\n",
    "            penalty=\"l2\",\n",
    "            C=1.0,\n",
    "            solver=\"lbfgs\",\n",
    "            max_iter=100,\n",
    "        )\n",
    "    ),\n",
    "    ClassifierConfig(\n",
    "        classifier=RandomForestClassifierConfig(\n",
    "            n_estimators=100,\n",
    "            max_depth=5,\n",
    "            min_samples_split=2,\n",
    "            min_samples_leaf=1,\n",
    "            random_state=42,\n",
    "        )\n",
    "    ),\n",
    "    ClassifierConfig(\n",
    "        classifier=HistGradientBoostingClassifierConfig(\n",
    "            learning_rate=0.1,\n",
    "            max_iter=100,\n",
    "            max_leaf_nodes=31,\n",
    "            min_samples_leaf=20,\n",
    "            random_state=42,\n",
    "        )\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Simulate cross-validation\n",
    "fold_name = \"fold\"\n",
    "train_df = df_physical.filter(pl.col(fold_name) == 0)\n",
    "val_df = df_physical.filter(pl.col(fold_name) == 1)\n",
    "test_df = df_physical.filter(pl.col(fold_name) == 2)\n",
    "\n",
    "# Evaluate each classifier configuration\n",
    "for classifier_config in classifier_configs:\n",
    "    print(f\"Evaluating {type(classifier_config.classifier).__name__}\")\n",
    "\n",
    "    # Create the pipeline\n",
    "    pipeline = create_pipeline(df_enum, input_config, classifier_config)\n",
    "\n",
    "    # Fit the pipeline on the training data\n",
    "    pipeline.fit(train_df.drop(fold_name), train_df[\"target\"])\n",
    "\n",
    "    # Evaluate the model on the validation and test data\n",
    "    val_accuracy = evaluate_model(pipeline, val_df.drop([fold_name, \"target\"]), val_df[\"target\"])\n",
    "    test_accuracy = evaluate_model(pipeline, test_df.drop([fold_name, \"target\"]), test_df[\"target\"])\n",
    "\n",
    "    print(\"Validation accuracy:\", val_accuracy)\n",
    "    print(\"Test accuracy:\", test_accuracy)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
