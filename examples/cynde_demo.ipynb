{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from typing import List\n",
    "from datetime import datetime\n",
    "import cynde.functional as cf\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")#\n",
    "client = openai.Client(api_key=api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get current path with os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_dir = os.getcwd()\n",
    "# Navigate one directory up to reach /cynde from /cynde/experiments\n",
    "parent_dir = os.path.dirname(script_dir)\n",
    "\n",
    "# Define the cache directory path as /cynde/cache\n",
    "cache_dir = os.path.join(parent_dir, \"cache\")\n",
    "\n",
    "\n",
    "# Ensure the cache directory exists, create if it doesn't\n",
    "os.makedirs(cache_dir, exist_ok=True)\n",
    "\n",
    "# Define file paths within the /cynde/cache directory\n",
    "requests_filepath = os.path.join(cache_dir, \"chat_payloads.jsonl\")\n",
    "emb_requests_filepath = os.path.join(cache_dir, \"chat_payloads_emb.jsonl\")\n",
    "\n",
    "results_filepath = os.path.join(cache_dir, \"openai_results.jsonl\")\n",
    "emb_results_file_path = os.path.join(cache_dir, \"openai_results_emb.jsonl\")\n",
    "requests_filepath_ = os.path.join(cache_dir, \"chat_payloads_.jsonl\")\n",
    "results_filepath_ = os.path.join(cache_dir, \"openai_results_.jsonl\")\n",
    "requests_filepath_tools = os.path.join(cache_dir, \"chat_payloads_tools.jsonl\")\n",
    "results_filepath_tools = os.path.join(cache_dir, \"openai_results_tools.jsonl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3, 4)\n",
      "┌─────────────┬───────────────────────────────────┬───────────┬─────────────────────┐\n",
      "│ customer_id ┆ feedback                          ┆ ratings   ┆ timestamp           │\n",
      "│ ---         ┆ ---                               ┆ ---       ┆ ---                 │\n",
      "│ i64         ┆ str                               ┆ list[i64] ┆ datetime[μs]        │\n",
      "╞═════════════╪═══════════════════════════════════╪═══════════╪═════════════════════╡\n",
      "│ 101         ┆ Loved the new product line!       ┆ [4, 5, 5] ┆ 2023-01-01 14:30:00 │\n",
      "│ 102         ┆ The service was disappointing th… ┆ [2, 3, 2] ┆ 2023-01-02 09:15:00 │\n",
      "│ 103         ┆ Great experience with customer s… ┆ [5, 4, 5] ┆ 2023-01-03 18:45:00 │\n",
      "└─────────────┴───────────────────────────────────┴───────────┴─────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "df = pl.DataFrame(\n",
    "    {\n",
    "        \"customer_id\": [101, 102, 103],\n",
    "        \"feedback\": [\n",
    "            \"Loved the new product line!\",\n",
    "            \"The service was disappointing this time.\",\n",
    "            \"Great experience with customer support.\",\n",
    "        ],\n",
    "        \"ratings\": [[4, 5, 5], [2, 3, 2], [5, 4, 5]],\n",
    "        \"timestamp\": [\n",
    "            datetime(2023, 1, 1, 14, 30),\n",
    "            datetime(2023, 1, 2, 9, 15),\n",
    "            datetime(2023, 1, 3, 18, 45),\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch API Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3, 5)\n",
      "┌─────────────┬───────────────────────────────┬───────────┬─────────────────────┬──────────────────┐\n",
      "│ customer_id ┆ feedback                      ┆ ratings   ┆ timestamp           ┆ customer_prompt  │\n",
      "│ ---         ┆ ---                           ┆ ---       ┆ ---                 ┆ ---              │\n",
      "│ i64         ┆ str                           ┆ list[i64] ┆ datetime[μs]        ┆ str              │\n",
      "╞═════════════╪═══════════════════════════════╪═══════════╪═════════════════════╪══════════════════╡\n",
      "│ 101         ┆ Loved the new product line!   ┆ [4, 5, 5] ┆ 2023-01-01 14:30:00 ┆ Customer ID: 101 │\n",
      "│             ┆                               ┆           ┆                     ┆ provided feedba… │\n",
      "│ 102         ┆ The service was disappointing ┆ [2, 3, 2] ┆ 2023-01-02 09:15:00 ┆ Customer ID: 102 │\n",
      "│             ┆ th…                           ┆           ┆                     ┆ provided feedba… │\n",
      "│ 103         ┆ Great experience with         ┆ [5, 4, 5] ┆ 2023-01-03 18:45:00 ┆ Customer ID: 103 │\n",
      "│             ┆ customer s…                   ┆           ┆                     ┆ provided feedba… │\n",
      "└─────────────┴───────────────────────────────┴───────────┴─────────────────────┴──────────────────┘\n",
      "Customer ID: 101 provided feedback at 14 with ratings 4-5-5 an average rating of 4.666666666666667 with a global mean of 3.8888888888888893: 'Loved the new product line!'\n",
      "Customer ID: 102 provided feedback at 9 with ratings 2-3-2 an average rating of 2.3333333333333335 with a global mean of 3.8888888888888893: 'The service was disappointing this time.'\n",
      "Customer ID: 103 provided feedback at 18 with ratings 5-4-5 an average rating of 4.666666666666667 with a global mean of 3.8888888888888893: 'Great experience with customer support.'\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Sample data frame initialization\n",
    "\n",
    "fstring = \"Customer ID: {} provided feedback at {} with ratings {} an average rating of {} with a global mean of {}: '{}'\"\n",
    "# Dynamic prompt generation with in-select computations\n",
    "\n",
    "df_prompted = cf.prompt(df, \n",
    "                     fstring,\n",
    "                     [pl.col(\"customer_id\"),\n",
    "                      pl.col(\"timestamp\").dt.hour(), #from timestamp to hour\n",
    "                      pl.col(\"ratings\").list.eval(pl.element().cast(pl.Utf8)).list.join(\"-\"), #needs to convert list columns to string\n",
    "                      pl.col(\"ratings\").list.mean(), #from list to float\n",
    "                      pl.col(\"ratings\").list.mean().mean(), #constant that gets broadcasted with pl.lit\n",
    "                      pl.col(\"feedback\")],\n",
    "                      \"customer_prompt\")\n",
    "print(df_prompted)\n",
    "for prompt in df_prompted[\"customer_prompt\"]:\n",
    "        print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Embedding API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cynde.functional.embed import embed_column, embed_columns\n",
    "from cynde.async_tools.api_request_parallel_processor import process_api_requests_from_file\n",
    "\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embed a single column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Starting request #0\n",
      "INFO:root:Starting request #1\n",
      "INFO:root:Starting request #2\n",
      "INFO:root:Parallel processing complete. Results saved to /Users/hk3user/Documents/Dev/Cynde/cache/openai_results_emb.jsonl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (30, 6)\n",
      "┌─────────────┬───────────────────┬───────────┬──────────────┬──────────────────┬──────────────────┐\n",
      "│ customer_id ┆ feedback          ┆ ratings   ┆ timestamp    ┆ customer_prompt  ┆ customer_prompt_ │\n",
      "│ ---         ┆ ---               ┆ ---       ┆ ---          ┆ ---              ┆ text-embedding-3 │\n",
      "│ i64         ┆ str               ┆ list[i64] ┆ datetime[μs] ┆ str              ┆ …                │\n",
      "│             ┆                   ┆           ┆              ┆                  ┆ ---              │\n",
      "│             ┆                   ┆           ┆              ┆                  ┆ list[f64]        │\n",
      "╞═════════════╪═══════════════════╪═══════════╪══════════════╪══════════════════╪══════════════════╡\n",
      "│ 101         ┆ Loved the new     ┆ [4, 5, 5] ┆ 2023-01-01   ┆ Customer ID: 101 ┆ [-0.01657,       │\n",
      "│             ┆ product line!     ┆           ┆ 14:30:00     ┆ provided feedba… ┆ 0.001133, …      │\n",
      "│             ┆                   ┆           ┆              ┆                  ┆ -0.042265…       │\n",
      "│ 101         ┆ Loved the new     ┆ [4, 5, 5] ┆ 2023-01-01   ┆ Customer ID: 101 ┆ [-0.01657,       │\n",
      "│             ┆ product line!     ┆           ┆ 14:30:00     ┆ provided feedba… ┆ 0.001133, …      │\n",
      "│             ┆                   ┆           ┆              ┆                  ┆ -0.042265…       │\n",
      "│ 101         ┆ Loved the new     ┆ [4, 5, 5] ┆ 2023-01-01   ┆ Customer ID: 101 ┆ [-0.01657,       │\n",
      "│             ┆ product line!     ┆           ┆ 14:30:00     ┆ provided feedba… ┆ 0.001133, …      │\n",
      "│             ┆                   ┆           ┆              ┆                  ┆ -0.042265…       │\n",
      "│ 101         ┆ Loved the new     ┆ [4, 5, 5] ┆ 2023-01-01   ┆ Customer ID: 101 ┆ [-0.01657,       │\n",
      "│             ┆ product line!     ┆           ┆ 14:30:00     ┆ provided feedba… ┆ 0.001133, …      │\n",
      "│             ┆                   ┆           ┆              ┆                  ┆ -0.042265…       │\n",
      "│ 101         ┆ Loved the new     ┆ [4, 5, 5] ┆ 2023-01-01   ┆ Customer ID: 101 ┆ [-0.01657,       │\n",
      "│             ┆ product line!     ┆           ┆ 14:30:00     ┆ provided feedba… ┆ 0.001133, …      │\n",
      "│             ┆                   ┆           ┆              ┆                  ┆ -0.042265…       │\n",
      "│ …           ┆ …                 ┆ …         ┆ …            ┆ …                ┆ …                │\n",
      "│ 103         ┆ Great experience  ┆ [5, 4, 5] ┆ 2023-01-03   ┆ Customer ID: 103 ┆ [-0.019291,      │\n",
      "│             ┆ with customer s…  ┆           ┆ 18:45:00     ┆ provided feedba… ┆ -0.001914, …     │\n",
      "│             ┆                   ┆           ┆              ┆                  ┆ -0.0262…         │\n",
      "│ 103         ┆ Great experience  ┆ [5, 4, 5] ┆ 2023-01-03   ┆ Customer ID: 103 ┆ [-0.019291,      │\n",
      "│             ┆ with customer s…  ┆           ┆ 18:45:00     ┆ provided feedba… ┆ -0.001914, …     │\n",
      "│             ┆                   ┆           ┆              ┆                  ┆ -0.0262…         │\n",
      "│ 103         ┆ Great experience  ┆ [5, 4, 5] ┆ 2023-01-03   ┆ Customer ID: 103 ┆ [-0.019291,      │\n",
      "│             ┆ with customer s…  ┆           ┆ 18:45:00     ┆ provided feedba… ┆ -0.001914, …     │\n",
      "│             ┆                   ┆           ┆              ┆                  ┆ -0.0262…         │\n",
      "│ 103         ┆ Great experience  ┆ [5, 4, 5] ┆ 2023-01-03   ┆ Customer ID: 103 ┆ [-0.019291,      │\n",
      "│             ┆ with customer s…  ┆           ┆ 18:45:00     ┆ provided feedba… ┆ -0.001914, …     │\n",
      "│             ┆                   ┆           ┆              ┆                  ┆ -0.0262…         │\n",
      "│ 103         ┆ Great experience  ┆ [5, 4, 5] ┆ 2023-01-03   ┆ Customer ID: 103 ┆ [-0.019291,      │\n",
      "│             ┆ with customer s…  ┆           ┆ 18:45:00     ┆ provided feedba… ┆ -0.001914, …     │\n",
      "│             ┆                   ┆           ┆              ┆                  ┆ -0.0262…         │\n",
      "└─────────────┴───────────────────┴───────────┴──────────────┴──────────────────┴──────────────────┘\n"
     ]
    }
   ],
   "source": [
    "merged_df = embed_column(df_prompted, \"customer_prompt\", emb_requests_filepath, emb_results_file_path, api_key, model_name=\"text-embedding-3-small\")\n",
    "print(merged_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embed Multiple Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Starting request #0\n",
      "INFO:root:Starting request #1\n",
      "INFO:root:Starting request #2\n",
      "INFO:root:Parallel processing complete. Results saved to /Users/hk3user/Documents/Dev/Cynde/cache/customer_prompt_text-embedding-3-small_results.jsonl\n",
      "INFO:root:Starting request #0\n",
      "INFO:root:Starting request #1\n",
      "INFO:root:Starting request #2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings for column 'customer_prompt' with model 'text-embedding-3-small' have been merged into the DataFrame.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Parallel processing complete. Results saved to /Users/hk3user/Documents/Dev/Cynde/cache/feedback_text-embedding-3-small_results.jsonl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings for column 'feedback' with model 'text-embedding-3-small' have been merged into the DataFrame.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>customer_id</th><th>feedback</th><th>ratings</th><th>timestamp</th><th>customer_prompt</th><th>customer_prompt_text-embedding-3-small_embedding</th><th>feedback_text-embedding-3-small_embedding</th></tr><tr><td>i64</td><td>str</td><td>list[i64]</td><td>datetime[μs]</td><td>str</td><td>list[f64]</td><td>list[f64]</td></tr></thead><tbody><tr><td>101</td><td>&quot;Loved the new …</td><td>[4, 5, 5]</td><td>2023-01-01 14:30:00</td><td>&quot;Customer ID: 1…</td><td>[-0.016553, 0.001147, … -0.042199]</td><td>[0.029176, -0.036259, … 0.000736]</td></tr><tr><td>102</td><td>&quot;The service wa…</td><td>[2, 3, 2]</td><td>2023-01-02 09:15:00</td><td>&quot;Customer ID: 1…</td><td>[-0.037493, 0.013733, … -0.030259]</td><td>[-0.005782, 0.019236, … -0.004272]</td></tr><tr><td>103</td><td>&quot;Great experien…</td><td>[5, 4, 5]</td><td>2023-01-03 18:45:00</td><td>&quot;Customer ID: 1…</td><td>[-0.019336, -0.001893, … -0.026274]</td><td>[-0.014194, -0.027349, … 0.021451]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 7)\n",
       "┌─────────────┬──────────────┬───────────┬──────────────┬──────────────┬─────────────┬─────────────┐\n",
       "│ customer_id ┆ feedback     ┆ ratings   ┆ timestamp    ┆ customer_pro ┆ customer_pr ┆ feedback_te │\n",
       "│ ---         ┆ ---          ┆ ---       ┆ ---          ┆ mpt          ┆ ompt_text-e ┆ xt-embeddin │\n",
       "│ i64         ┆ str          ┆ list[i64] ┆ datetime[μs] ┆ ---          ┆ mbedding-3… ┆ g-3-small_… │\n",
       "│             ┆              ┆           ┆              ┆ str          ┆ ---         ┆ ---         │\n",
       "│             ┆              ┆           ┆              ┆              ┆ list[f64]   ┆ list[f64]   │\n",
       "╞═════════════╪══════════════╪═══════════╪══════════════╪══════════════╪═════════════╪═════════════╡\n",
       "│ 101         ┆ Loved the    ┆ [4, 5, 5] ┆ 2023-01-01   ┆ Customer ID: ┆ [-0.016553, ┆ [0.029176,  │\n",
       "│             ┆ new product  ┆           ┆ 14:30:00     ┆ 101 provided ┆ 0.001147, … ┆ -0.036259,  │\n",
       "│             ┆ line!        ┆           ┆              ┆ feedba…      ┆ -0.04219…   ┆ … 0.000736… │\n",
       "│ 102         ┆ The service  ┆ [2, 3, 2] ┆ 2023-01-02   ┆ Customer ID: ┆ [-0.037493, ┆ [-0.005782, │\n",
       "│             ┆ was disappoi ┆           ┆ 09:15:00     ┆ 102 provided ┆ 0.013733, … ┆ 0.019236, … │\n",
       "│             ┆ nting th…    ┆           ┆              ┆ feedba…      ┆ -0.03025…   ┆ -0.00427…   │\n",
       "│ 103         ┆ Great        ┆ [5, 4, 5] ┆ 2023-01-03   ┆ Customer ID: ┆ [-0.019336, ┆ [-0.014194, │\n",
       "│             ┆ experience   ┆           ┆ 18:45:00     ┆ 103 provided ┆ -0.001893,  ┆ -0.027349,  │\n",
       "│             ┆ with         ┆           ┆              ┆ feedba…      ┆ … -0.0262…  ┆ … 0.02145…  │\n",
       "│             ┆ customer s…  ┆           ┆              ┆              ┆             ┆             │\n",
       "└─────────────┴──────────────┴───────────┴──────────────┴──────────────┴─────────────┴─────────────┘"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_columns(df=df_prompted, column_names=[\"customer_prompt\", \"feedback\"], models=[\"text-embedding-3-small\"], api_key=api_key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Chat Completion API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cynde.functional.generate import generate_chat_completion_payloads, generate_chat_payloads_from_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"Evaluate the following customer feedback return a True or False based on the sentiment:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Pydantic Model inside None\n",
      "shape: (3, 2)\n",
      "┌───────────────────────────────────┬───────────────────────────────────┐\n",
      "│ customer_prompt                   ┆ str_messages                      │\n",
      "│ ---                               ┆ ---                               │\n",
      "│ str                               ┆ str                               │\n",
      "╞═══════════════════════════════════╪═══════════════════════════════════╡\n",
      "│ Customer ID: 101 provided feedba… ┆ {\"role\":\"system\",\"content\":\"Eval… │\n",
      "│ Customer ID: 102 provided feedba… ┆ {\"role\":\"system\",\"content\":\"Eval… │\n",
      "│ Customer ID: 103 provided feedba… ┆ {\"role\":\"system\",\"content\":\"Eval… │\n",
      "└───────────────────────────────────┴───────────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "payload_df = generate_chat_payloads_from_column(requests_filepath, df_prompted, \"customer_prompt\", system_prompt)\n",
    "print(payload_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nest_asyncio.apply()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cynde.functional.generate import process_and_merge_llm_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Starting request #0\n",
      "INFO:root:Starting request #1\n",
      "INFO:root:Starting request #2\n",
      "INFO:root:Parallel processing complete. Results saved to c:\\Users\\Tommaso\\Documents\\Dev\\Cynde\\cache\\openai_results.jsonl\n"
     ]
    }
   ],
   "source": [
    "request_url = \"https://api.openai.com/v1/chat/completions\"  # Replace with your actual API endpoint\n",
    "    # Process multiple api requests to ChatGPT\n",
    "asyncio.run(\n",
    "    process_api_requests_from_file(\n",
    "        requests_filepath=requests_filepath,\n",
    "        save_filepath=results_filepath,\n",
    "        request_url=request_url,\n",
    "        api_key=api_key,\n",
    "        max_requests_per_minute=float(90000),\n",
    "        max_tokens_per_minute=float(170000),\n",
    "        token_encoding_name=\"cl100k_base\",\n",
    "        max_attempts=int(5),\n",
    "        logging_level=int(20),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cynde.functional.generate import merge_df_with_openai_results,load_openai_results_jsonl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3, 5)\n",
      "┌─────────────────────┬─────────────────────┬───────────┬─────────────────────┬────────────────────┐\n",
      "│ messages            ┆ choices             ┆ usage     ┆ results             ┆ str_messages       │\n",
      "│ ---                 ┆ ---                 ┆ ---       ┆ ---                 ┆ ---                │\n",
      "│ list[struct[2]]     ┆ struct[2]           ┆ struct[3] ┆ struct[7]           ┆ str                │\n",
      "╞═════════════════════╪═════════════════════╪═══════════╪═════════════════════╪════════════════════╡\n",
      "│ [{\"system\",\"Evaluat ┆ {\"assistant\",\"False ┆ {80,1,81} ┆ {\"chatcmpl-8ohMf68J ┆ {\"role\":\"system\",\" │\n",
      "│ e the followi…      ┆ \"}                  ┆           ┆ VYbra9wxtdR4P…      ┆ content\":\"Eval…    │\n",
      "│ [{\"system\",\"Evaluat ┆ {\"assistant\",\"True\" ┆ {78,1,79} ┆ {\"chatcmpl-8ohMfqjH ┆ {\"role\":\"system\",\" │\n",
      "│ e the followi…      ┆ }                   ┆           ┆ JfCA8LIfCZuxc…      ┆ content\":\"Eval…    │\n",
      "│ [{\"system\",\"Evaluat ┆ {\"assistant\",\"True\" ┆ {79,1,80} ┆ {\"chatcmpl-8ohMgNc5 ┆ {\"role\":\"system\",\" │\n",
      "│ e the followi…      ┆ }                   ┆           ┆ eVHGEy8N7lZpz…      ┆ content\":\"Eval…    │\n",
      "└─────────────────────┴─────────────────────┴───────────┴─────────────────────┴────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "results_df = load_openai_results_jsonl(results_filepath)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3, 10)\n",
      "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
      "│ customer_ ┆ feedback  ┆ ratings   ┆ timestamp ┆ … ┆ messages  ┆ choices   ┆ usage     ┆ results  │\n",
      "│ id        ┆ ---       ┆ ---       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
      "│ ---       ┆ str       ┆ list[i64] ┆ datetime[ ┆   ┆ list[stru ┆ struct[2] ┆ struct[3] ┆ struct[7 │\n",
      "│ i64       ┆           ┆           ┆ μs]       ┆   ┆ ct[2]]    ┆           ┆           ┆ ]        │\n",
      "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
      "│ 101       ┆ Loved the ┆ [4, 5, 5] ┆ 2023-01-0 ┆ … ┆ [{\"system ┆ {\"assista ┆ {79,1,80} ┆ {\"chatcm │\n",
      "│           ┆ new       ┆           ┆ 1         ┆   ┆ \",\"Evalua ┆ nt\",\"True ┆           ┆ pl-8ohMg │\n",
      "│           ┆ product   ┆           ┆ 14:30:00  ┆   ┆ te the    ┆ \"}        ┆           ┆ Nc5eVHGE │\n",
      "│           ┆ line!     ┆           ┆           ┆   ┆ followi…  ┆           ┆           ┆ y8N7lZpz │\n",
      "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ …        │\n",
      "│ 102       ┆ The       ┆ [2, 3, 2] ┆ 2023-01-0 ┆ … ┆ [{\"system ┆ {\"assista ┆ {80,1,81} ┆ {\"chatcm │\n",
      "│           ┆ service   ┆           ┆ 2         ┆   ┆ \",\"Evalua ┆ nt\",\"Fals ┆           ┆ pl-8ohMf │\n",
      "│           ┆ was disap ┆           ┆ 09:15:00  ┆   ┆ te the    ┆ e\"}       ┆           ┆ 68JVYbra │\n",
      "│           ┆ pointing  ┆           ┆           ┆   ┆ followi…  ┆           ┆           ┆ 9wxtdR4P │\n",
      "│           ┆ th…       ┆           ┆           ┆   ┆           ┆           ┆           ┆ …        │\n",
      "│ 103       ┆ Great exp ┆ [5, 4, 5] ┆ 2023-01-0 ┆ … ┆ [{\"system ┆ {\"assista ┆ {78,1,79} ┆ {\"chatcm │\n",
      "│           ┆ erience   ┆           ┆ 3         ┆   ┆ \",\"Evalua ┆ nt\",\"True ┆           ┆ pl-8ohMf │\n",
      "│           ┆ with      ┆           ┆ 18:45:00  ┆   ┆ te the    ┆ \"}        ┆           ┆ qjHJfCA8 │\n",
      "│           ┆ customer  ┆           ┆           ┆   ┆ followi…  ┆           ┆           ┆ LIfCZuxc │\n",
      "│           ┆ s…        ┆           ┆           ┆   ┆           ┆           ┆           ┆ …        │\n",
      "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "merged_df = merge_df_with_openai_results(df_prompted, payload_df, results_df, \"customer_prompt\")\n",
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Starting request #0\n",
      "INFO:root:Starting request #1\n",
      "INFO:root:Starting request #2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating chat completion payloads...\n",
      "Using Pydantic Model before calling None\n",
      "Using Pydantic Model inside None\n",
      "Chat completion payloads generated in 0.00 seconds.\n",
      "Processing chat completion payloads with the LLM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Parallel processing complete. Results saved to c:\\Users\\Tommaso\\Documents\\Dev\\Cynde\\cache\\openai_results_.jsonl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat completion payloads processed in 0.53 seconds.\n",
      "Loading results from LLM processing...\n",
      "Results loaded in 0.01 seconds.\n",
      "Merging LLM results back into the original DataFrame...\n",
      "LLM results merged in 0.00 seconds.\n",
      "Total process completed in 0.54 seconds.\n",
      "shape: (3, 10)\n",
      "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
      "│ customer_ ┆ feedback  ┆ ratings   ┆ timestamp ┆ … ┆ messages  ┆ choices   ┆ usage     ┆ results  │\n",
      "│ id        ┆ ---       ┆ ---       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
      "│ ---       ┆ str       ┆ list[i64] ┆ datetime[ ┆   ┆ list[stru ┆ struct[2] ┆ struct[3] ┆ struct[7 │\n",
      "│ i64       ┆           ┆           ┆ μs]       ┆   ┆ ct[2]]    ┆           ┆           ┆ ]        │\n",
      "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
      "│ 101       ┆ Loved the ┆ [4, 5, 5] ┆ 2023-01-0 ┆ … ┆ [{\"system ┆ {\"assista ┆ {79,1,80} ┆ {\"chatcm │\n",
      "│           ┆ new       ┆           ┆ 1         ┆   ┆ \",\"Evalua ┆ nt\",\"True ┆           ┆ pl-8ohMg │\n",
      "│           ┆ product   ┆           ┆ 14:30:00  ┆   ┆ te the    ┆ \"}        ┆           ┆ YXJGFGcu │\n",
      "│           ┆ line!     ┆           ┆           ┆   ┆ followi…  ┆           ┆           ┆ 4OrB8tJ8 │\n",
      "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ …        │\n",
      "│ 102       ┆ The       ┆ [2, 3, 2] ┆ 2023-01-0 ┆ … ┆ [{\"system ┆ {\"assista ┆ {80,1,81} ┆ {\"chatcm │\n",
      "│           ┆ service   ┆           ┆ 2         ┆   ┆ \",\"Evalua ┆ nt\",\"Fals ┆           ┆ pl-8ohMg │\n",
      "│           ┆ was disap ┆           ┆ 09:15:00  ┆   ┆ te the    ┆ e\"}       ┆           ┆ oNKaMWdM │\n",
      "│           ┆ pointing  ┆           ┆           ┆   ┆ followi…  ┆           ┆           ┆ f8acBmbW │\n",
      "│           ┆ th…       ┆           ┆           ┆   ┆           ┆           ┆           ┆ …        │\n",
      "│ 103       ┆ Great exp ┆ [5, 4, 5] ┆ 2023-01-0 ┆ … ┆ [{\"system ┆ {\"assista ┆ {78,1,79} ┆ {\"chatcm │\n",
      "│           ┆ erience   ┆           ┆ 3         ┆   ┆ \",\"Evalua ┆ nt\",\"True ┆           ┆ pl-8ohMg │\n",
      "│           ┆ with      ┆           ┆ 18:45:00  ┆   ┆ te the    ┆ \"}        ┆           ┆ WjYgZZ2B │\n",
      "│           ┆ customer  ┆           ┆           ┆   ┆ followi…  ┆           ┆           ┆ rfPJdldk │\n",
      "│           ┆ s…        ┆           ┆           ┆   ┆           ┆           ┆           ┆ …        │\n",
      "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "merged_df = process_and_merge_llm_responses(df= df_prompted,\n",
    "                                column_name= \"customer_prompt\",\n",
    "                                system_prompt = system_prompt,\n",
    "                                requests_filepath = requests_filepath_,\n",
    "                                results_filepath = results_filepath_,\n",
    "                                api_key=api_key,)\n",
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from instructor.function_calls import openai_schema\n",
    "from pydantic import BaseModel, Field\n",
    "import enum\n",
    "from typing import Optional, List\n",
    "from cynde.utils.expressions import list_struct_to_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomerSentimentLabels(str, enum.Enum):\n",
    "    \"\"\"Enumeration for single-label customer sentiment classification.\"\"\"\n",
    "    POS = \"PositiveCustomerSentiment\"\n",
    "    NEG = \"NegativeCustomerSentiment\"\n",
    "\n",
    "class SentimentLabeller(BaseModel):\n",
    "    \"\"\"\n",
    "    Class for a single class label prediction.\n",
    "    \"\"\"\n",
    "    class_label: CustomerSentimentLabels\n",
    "    extra_details: Optional[str] = Field(None, description=\"Extra details used for the prediction.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Starting request #0\n",
      "INFO:root:Starting request #1\n",
      "INFO:root:Starting request #2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating chat completion payloads...\n",
      "Using Pydantic Model before calling <class '__main__.SentimentLabeller'>\n",
      "Using Pydantic Model inside <class '__main__.SentimentLabeller'>\n",
      "Using Pydantic Model\n",
      "Using Function Calling SentimentLabeller\n",
      "Chat completion payloads generated in 0.00 seconds.\n",
      "Processing chat completion payloads with the LLM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Parallel processing complete. Results saved to c:\\Users\\Tommaso\\Documents\\Dev\\Cynde\\cache\\openai_results_tools.jsonl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat completion payloads processed in 0.60 seconds.\n",
      "Loading results from LLM processing...\n",
      "Results loaded in 0.01 seconds.\n",
      "Merging LLM results back into the original DataFrame...\n",
      "LLM results merged in 0.00 seconds.\n",
      "Total process completed in 0.61 seconds.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (6,)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>choices</th></tr><tr><td>struct[3]</td></tr></thead><tbody><tr><td>{&quot;assistant&quot;,null,[{&quot;call_s4iKZka6P5AxzMDphu4oJpHa&quot;,&quot;function&quot;,{&quot;SentimentLabeller&quot;,&quot;{&quot;class_label&quot;:&quot;PositiveCustomerSentiment&quot;}&quot;}}]}</td></tr><tr><td>{&quot;assistant&quot;,null,[{&quot;call_xmbr4alXiv5WNqkR0fgu5uwo&quot;,&quot;function&quot;,{&quot;SentimentLabeller&quot;,&quot;{&quot;class_label&quot;:&quot;PositiveCustomerSentiment&quot;}&quot;}}]}</td></tr><tr><td>{&quot;assistant&quot;,null,[{&quot;call_AbVq7oJXx97ayU6xNruIpCnR&quot;,&quot;function&quot;,{&quot;SentimentLabeller&quot;,&quot;{&quot;class_label&quot;:&quot;NegativeCustomerSentiment&quot;}&quot;}}]}</td></tr><tr><td>{&quot;assistant&quot;,null,[{&quot;call_FUyXnrvlrWACvp3IHce5Nb7x&quot;,&quot;function&quot;,{&quot;SentimentLabeller&quot;,&quot;{&quot;class_label&quot;:&quot;NegativeCustomerSentiment&quot;}&quot;}}]}</td></tr><tr><td>{&quot;assistant&quot;,null,[{&quot;call_bP7y8aLMA7i8kgchpQDIGaCL&quot;,&quot;function&quot;,{&quot;SentimentLabeller&quot;,&quot;{&quot;class_label&quot;:&quot;PositiveCustomerSentiment&quot;}&quot;}}]}</td></tr><tr><td>{&quot;assistant&quot;,null,[{&quot;call_SCttvGUCIv7xDt0ed73oDS3X&quot;,&quot;function&quot;,{&quot;SentimentLabeller&quot;,&quot;{&quot;class_label&quot;:&quot;PositiveCustomerSentiment&quot;}&quot;}}]}</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (6,)\n",
       "Series: 'choices' [struct[3]]\n",
       "[\n",
       "\t{\"assistant\",null,[{\"call_s4iKZka6P5AxzMDphu4oJpHa\",\"function\",{\"SentimentLabeller\",\"{\"class_label\":\"PositiveCustomerSentiment\"}\"}}]}\n",
       "\t{\"assistant\",null,[{\"call_xmbr4alXiv5WNqkR0fgu5uwo\",\"function\",{\"SentimentLabeller\",\"{\"class_label\":\"PositiveCustomerSentiment\"}\"}}]}\n",
       "\t{\"assistant\",null,[{\"call_AbVq7oJXx97ayU6xNruIpCnR\",\"function\",{\"SentimentLabeller\",\"{\"class_label\":\"NegativeCustomerSentiment\"}\"}}]}\n",
       "\t{\"assistant\",null,[{\"call_FUyXnrvlrWACvp3IHce5Nb7x\",\"function\",{\"SentimentLabeller\",\"{\"class_label\":\"NegativeCustomerSentiment\"}\"}}]}\n",
       "\t{\"assistant\",null,[{\"call_bP7y8aLMA7i8kgchpQDIGaCL\",\"function\",{\"SentimentLabeller\",\"{\"class_label\":\"PositiveCustomerSentiment\"}\"}}]}\n",
       "\t{\"assistant\",null,[{\"call_SCttvGUCIv7xDt0ed73oDS3X\",\"function\",{\"SentimentLabeller\",\"{\"class_label\":\"PositiveCustomerSentiment\"}\"}}]}\n",
       "]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df_funct = process_and_merge_llm_responses(df= df_prompted,\n",
    "                                column_name= \"customer_prompt\",\n",
    "                                system_prompt = system_prompt,\n",
    "                                requests_filepath = requests_filepath_tools,\n",
    "                                results_filepath = results_filepath_tools,\n",
    "                                pydantic_model=SentimentLabeller,\n",
    "                                api_key=api_key,)\n",
    "merged_df_funct[\"choices\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = openai_schema(SentimentLabeller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_label=<CustomerSentimentLabels.POS: 'PositiveCustomerSentiment'> extra_details=None\n",
      "class_label=<CustomerSentimentLabels.POS: 'PositiveCustomerSentiment'> extra_details=None\n",
      "class_label=<CustomerSentimentLabels.NEG: 'NegativeCustomerSentiment'> extra_details=None\n"
     ]
    }
   ],
   "source": [
    "from cynde.functional.generate import load_openai_results_jsonl_pydantic\n",
    "from pydantic import ValidationError\n",
    "\n",
    "# Load and parse the file\n",
    "completions = load_openai_results_jsonl_pydantic(results_filepath_tools)\n",
    "pydantic_objects = []\n",
    "# Print or process the loaded completions as needed\n",
    "for completion in completions:\n",
    "    try:\n",
    "        out = schema.from_response(completion)\n",
    "        print(out)\n",
    "        pydantic_objects.append(out)\n",
    "    except ValidationError as e:\n",
    "        print(e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
