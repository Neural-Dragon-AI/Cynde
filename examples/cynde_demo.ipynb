{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from typing import List\n",
    "from datetime import datetime\n",
    "import cynde.functional as cf\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")#\n",
    "client = openai.Client(api_key=api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get current path with os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_dir = os.getcwd()\n",
    "# Navigate one directory up to reach /cynde from /cynde/experiments\n",
    "parent_dir = os.path.dirname(script_dir)\n",
    "\n",
    "# Define the cache directory path as /cynde/cache\n",
    "cache_dir = os.path.join(parent_dir, \"cache\")\n",
    "\n",
    "# Ensure the cache directory exists, create if it doesn't\n",
    "os.makedirs(cache_dir, exist_ok=True)\n",
    "\n",
    "# Define file paths within the /cynde/cache directory\n",
    "requests_filepath = os.path.join(cache_dir, \"chat_payloads.jsonl\")\n",
    "emb_requests_filepath = os.path.join(cache_dir, \"chat_payloads_emb.jsonl\")\n",
    "\n",
    "results_filepath = os.path.join(cache_dir, \"openai_results.jsonl\")\n",
    "emb_results_file_path = os.path.join(cache_dir, \"openai_results_emb.jsonl\")\n",
    "requests_filepath_ = os.path.join(cache_dir, \"chat_payloads_.jsonl\")\n",
    "results_filepath_ = os.path.join(cache_dir, \"openai_results_.jsonl\")\n",
    "requests_filepath_tools = os.path.join(cache_dir, \"chat_payloads_tools.jsonl\")\n",
    "results_filepath_tools = os.path.join(cache_dir, \"openai_results_tools.jsonl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3, 4)\n",
      "┌─────────────┬───────────────────────────────────┬───────────┬─────────────────────┐\n",
      "│ customer_id ┆ feedback                          ┆ ratings   ┆ timestamp           │\n",
      "│ ---         ┆ ---                               ┆ ---       ┆ ---                 │\n",
      "│ i64         ┆ str                               ┆ list[i64] ┆ datetime[μs]        │\n",
      "╞═════════════╪═══════════════════════════════════╪═══════════╪═════════════════════╡\n",
      "│ 101         ┆ Loved the new product line!       ┆ [4, 5, 5] ┆ 2023-01-01 14:30:00 │\n",
      "│ 102         ┆ The service was disappointing th… ┆ [2, 3, 2] ┆ 2023-01-02 09:15:00 │\n",
      "│ 103         ┆ Great experience with customer s… ┆ [5, 4, 5] ┆ 2023-01-03 18:45:00 │\n",
      "└─────────────┴───────────────────────────────────┴───────────┴─────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "df = pl.DataFrame(\n",
    "    {\n",
    "        \"customer_id\": [101, 102, 103],\n",
    "        \"feedback\": [\n",
    "            \"Loved the new product line!\",\n",
    "            \"The service was disappointing this time.\",\n",
    "            \"Great experience with customer support.\",\n",
    "        ],\n",
    "        \"ratings\": [[4, 5, 5], [2, 3, 2], [5, 4, 5]],\n",
    "        \"timestamp\": [\n",
    "            datetime(2023, 1, 1, 14, 30),\n",
    "            datetime(2023, 1, 2, 9, 15),\n",
    "            datetime(2023, 1, 3, 18, 45),\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Legacy Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating embeddings for column feedback\n",
      "Processing 3 chunks of text in a single batch\n",
      "Embedding Processing took 0.8668673038482666 seconds\n",
      "shape: (3, 5)\n",
      "┌─────────────┬─────────────────────────┬───────────┬─────────────────────┬────────────────────────┐\n",
      "│ customer_id ┆ feedback                ┆ ratings   ┆ timestamp           ┆ feedback_text-embeddin │\n",
      "│ ---         ┆ ---                     ┆ ---       ┆ ---                 ┆ g-3-small_…            │\n",
      "│ i64         ┆ str                     ┆ list[i64] ┆ datetime[μs]        ┆ ---                    │\n",
      "│             ┆                         ┆           ┆                     ┆ list[f64]              │\n",
      "╞═════════════╪═════════════════════════╪═══════════╪═════════════════════╪════════════════════════╡\n",
      "│ 101         ┆ Loved the new product   ┆ [4, 5, 5] ┆ 2023-01-01 14:30:00 ┆ [0.029205, -0.036287,  │\n",
      "│             ┆ line!                   ┆           ┆                     ┆ … 0.000765…            │\n",
      "│ 102         ┆ The service was         ┆ [2, 3, 2] ┆ 2023-01-02 09:15:00 ┆ [-0.005782, 0.019236,  │\n",
      "│             ┆ disappointing th…       ┆           ┆                     ┆ … -0.00427…            │\n",
      "│ 103         ┆ Great experience with   ┆ [5, 4, 5] ┆ 2023-01-03 18:45:00 ┆ [-0.014194, -0.027349, │\n",
      "│             ┆ customer s…             ┆           ┆                     ┆ … 0.02145…             │\n",
      "└─────────────┴─────────────────────────┴───────────┴─────────────────────┴────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "embedded_df = cf.embed_columns(df, [\"feedback\"], client=client)\n",
    "print(embedded_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch API Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3, 6)\n",
      "┌─────────────┬───────────────────┬───────────┬──────────────┬──────────────────┬──────────────────┐\n",
      "│ customer_id ┆ feedback          ┆ ratings   ┆ timestamp    ┆ feedback_text-em ┆ customer_prompt  │\n",
      "│ ---         ┆ ---               ┆ ---       ┆ ---          ┆ bedding-3-small_ ┆ ---              │\n",
      "│ i64         ┆ str               ┆ list[i64] ┆ datetime[μs] ┆ …                ┆ str              │\n",
      "│             ┆                   ┆           ┆              ┆ ---              ┆                  │\n",
      "│             ┆                   ┆           ┆              ┆ list[f64]        ┆                  │\n",
      "╞═════════════╪═══════════════════╪═══════════╪══════════════╪══════════════════╪══════════════════╡\n",
      "│ 101         ┆ Loved the new     ┆ [4, 5, 5] ┆ 2023-01-01   ┆ [0.029205,       ┆ Customer ID: 101 │\n",
      "│             ┆ product line!     ┆           ┆ 14:30:00     ┆ -0.036287, …     ┆ provided feedba… │\n",
      "│             ┆                   ┆           ┆              ┆ 0.000765…        ┆                  │\n",
      "│ 102         ┆ The service was   ┆ [2, 3, 2] ┆ 2023-01-02   ┆ [-0.005782,      ┆ Customer ID: 102 │\n",
      "│             ┆ disappointing th… ┆           ┆ 09:15:00     ┆ 0.019236, …      ┆ provided feedba… │\n",
      "│             ┆                   ┆           ┆              ┆ -0.00427…        ┆                  │\n",
      "│ 103         ┆ Great experience  ┆ [5, 4, 5] ┆ 2023-01-03   ┆ [-0.014194,      ┆ Customer ID: 103 │\n",
      "│             ┆ with customer s…  ┆           ┆ 18:45:00     ┆ -0.027349, …     ┆ provided feedba… │\n",
      "│             ┆                   ┆           ┆              ┆ 0.02145…         ┆                  │\n",
      "└─────────────┴───────────────────┴───────────┴──────────────┴──────────────────┴──────────────────┘\n",
      "Customer ID: 101 provided feedback at 14 with ratings 4-5-5 an average rating of 4.666666666666667 with a global mean of 3.8888888888888893: 'Loved the new product line!'\n",
      "Customer ID: 102 provided feedback at 9 with ratings 2-3-2 an average rating of 2.3333333333333335 with a global mean of 3.8888888888888893: 'The service was disappointing this time.'\n",
      "Customer ID: 103 provided feedback at 18 with ratings 5-4-5 an average rating of 4.666666666666667 with a global mean of 3.8888888888888893: 'Great experience with customer support.'\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Sample data frame initialization\n",
    "\n",
    "fstring = \"Customer ID: {} provided feedback at {} with ratings {} an average rating of {} with a global mean of {}: '{}'\"\n",
    "# Dynamic prompt generation with in-select computations\n",
    "\n",
    "df_prompted = cf.prompt(embedded_df, \n",
    "                     fstring,\n",
    "                     [pl.col(\"customer_id\"),\n",
    "                      pl.col(\"timestamp\").dt.hour(), #from timestamp to hour\n",
    "                      pl.col(\"ratings\").list.eval(pl.element().cast(pl.Utf8)).list.join(\"-\"), #needs to convert list columns to string\n",
    "                      pl.col(\"ratings\").list.mean(), #from list to float\n",
    "                      pl.col(\"ratings\").list.mean().mean(), #constant that gets broadcasted with pl.lit\n",
    "                      pl.col(\"feedback\")],\n",
    "                      \"customer_prompt\")\n",
    "print(df_prompted)\n",
    "for prompt in df_prompted[\"customer_prompt\"]:\n",
    "        print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Embedding API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cynde.functional.embed import generate_embedding_payloads_from_column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3, 3)\n",
      "┌───────────────────────────────────┬────────────────────────┬───────────────────────────────────┐\n",
      "│ customer_prompt                   ┆ model                  ┆ input                             │\n",
      "│ ---                               ┆ ---                    ┆ ---                               │\n",
      "│ str                               ┆ str                    ┆ str                               │\n",
      "╞═══════════════════════════════════╪════════════════════════╪═══════════════════════════════════╡\n",
      "│ Customer ID: 101 provided feedba… ┆ text-embedding-3-small ┆ Customer ID: 101 provided feedba… │\n",
      "│ Customer ID: 102 provided feedba… ┆ text-embedding-3-small ┆ Customer ID: 102 provided feedba… │\n",
      "│ Customer ID: 103 provided feedba… ┆ text-embedding-3-small ┆ Customer ID: 103 provided feedba… │\n",
      "└───────────────────────────────────┴────────────────────────┴───────────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "emb_payload_df = generate_embedding_payloads_from_column(emb_requests_filepath, df_prompted, \"customer_prompt\", model_name=\"text-embedding-3-small\")\n",
    "print(emb_payload_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import asyncio\n",
    "from cynde.async_tools.api_request_parallel_processor import process_api_requests_from_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Starting request #0\n",
      "INFO:root:Starting request #1\n",
      "INFO:root:Starting request #2\n",
      "INFO:root:Parallel processing complete. Results saved to /Users/hk3user/Documents/Dev/Cynde/cache/openai_results_emb.jsonl\n"
     ]
    }
   ],
   "source": [
    "request_url = \"https://api.openai.com/v1/embeddings\"  # Replace with your actual API endpoint\n",
    "    # Process multiple api requests to ChatGPT\n",
    "asyncio.run(\n",
    "    process_api_requests_from_file(\n",
    "        requests_filepath=emb_requests_filepath,\n",
    "        save_filepath=emb_results_file_path,\n",
    "        request_url=request_url,\n",
    "        api_key=api_key,\n",
    "        max_requests_per_minute=float(90000),\n",
    "        max_tokens_per_minute=float(10_000_000),\n",
    "        token_encoding_name=\"cl100k_base\",\n",
    "        max_attempts=int(5),\n",
    "        logging_level=int(20),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cynde.functional.embed import load_openai_emb_results_jsonl, merge_df_with_openai_emb_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = load_openai_emb_results_jsonl(emb_results_file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model</th><th>input</th><th>embedding</th></tr><tr><td>str</td><td>str</td><td>list[f64]</td></tr></thead><tbody><tr><td>&quot;text-embedding…</td><td>&quot;Customer ID: 1…</td><td>[-0.01657, 0.001133, … -0.042265]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 3)\n",
       "┌────────────────────────┬───────────────────────────────────┬───────────────────────────────────┐\n",
       "│ model                  ┆ input                             ┆ embedding                         │\n",
       "│ ---                    ┆ ---                               ┆ ---                               │\n",
       "│ str                    ┆ str                               ┆ list[f64]                         │\n",
       "╞════════════════════════╪═══════════════════════════════════╪═══════════════════════════════════╡\n",
       "│ text-embedding-3-small ┆ Customer ID: 101 provided feedba… ┆ [-0.01657, 0.001133, … -0.042265… │\n",
       "└────────────────────────┴───────────────────────────────────┴───────────────────────────────────┘"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>customer_prompt</th><th>model</th><th>input</th></tr><tr><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;Customer ID: 1…</td><td>&quot;text-embedding…</td><td>&quot;Customer ID: 1…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 3)\n",
       "┌───────────────────────────────────┬────────────────────────┬───────────────────────────────────┐\n",
       "│ customer_prompt                   ┆ model                  ┆ input                             │\n",
       "│ ---                               ┆ ---                    ┆ ---                               │\n",
       "│ str                               ┆ str                    ┆ str                               │\n",
       "╞═══════════════════════════════════╪════════════════════════╪═══════════════════════════════════╡\n",
       "│ Customer ID: 101 provided feedba… ┆ text-embedding-3-small ┆ Customer ID: 101 provided feedba… │\n",
       "└───────────────────────────────────┴────────────────────────┴───────────────────────────────────┘"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_payload_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>customer_id</th><th>feedback</th><th>ratings</th><th>timestamp</th><th>feedback_text-embedding-3-small_embeddings</th><th>customer_prompt</th></tr><tr><td>i64</td><td>str</td><td>list[i64]</td><td>datetime[μs]</td><td>list[f64]</td><td>str</td></tr></thead><tbody><tr><td>101</td><td>&quot;Loved the new …</td><td>[4, 5, 5]</td><td>2023-01-01 14:30:00</td><td>[0.029205, -0.036287, … 0.000765]</td><td>&quot;Customer ID: 1…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 6)\n",
       "┌─────────────┬───────────────┬───────────┬──────────────┬────────────────────┬────────────────────┐\n",
       "│ customer_id ┆ feedback      ┆ ratings   ┆ timestamp    ┆ feedback_text-embe ┆ customer_prompt    │\n",
       "│ ---         ┆ ---           ┆ ---       ┆ ---          ┆ dding-3-small_…    ┆ ---                │\n",
       "│ i64         ┆ str           ┆ list[i64] ┆ datetime[μs] ┆ ---                ┆ str                │\n",
       "│             ┆               ┆           ┆              ┆ list[f64]          ┆                    │\n",
       "╞═════════════╪═══════════════╪═══════════╪══════════════╪════════════════════╪════════════════════╡\n",
       "│ 101         ┆ Loved the new ┆ [4, 5, 5] ┆ 2023-01-01   ┆ [0.029205,         ┆ Customer ID: 101   │\n",
       "│             ┆ product line! ┆           ┆ 14:30:00     ┆ -0.036287, …       ┆ provided feedba…   │\n",
       "│             ┆               ┆           ┆              ┆ 0.000765…          ┆                    │\n",
       "└─────────────┴───────────────┴───────────┴──────────────┴────────────────────┴────────────────────┘"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prompted.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3, 10)\n",
      "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
      "│ customer_ ┆ feedback  ┆ ratings   ┆ timestamp ┆ … ┆ model     ┆ input     ┆ model_rig ┆ embeddin │\n",
      "│ id        ┆ ---       ┆ ---       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ht        ┆ g        │\n",
      "│ ---       ┆ str       ┆ list[i64] ┆ datetime[ ┆   ┆ str       ┆ str       ┆ ---       ┆ ---      │\n",
      "│ i64       ┆           ┆           ┆ μs]       ┆   ┆           ┆           ┆ str       ┆ list[f64 │\n",
      "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ ]        │\n",
      "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
      "│ 101       ┆ Loved the ┆ [4, 5, 5] ┆ 2023-01-0 ┆ … ┆ text-embe ┆ Customer  ┆ text-embe ┆ [-0.0165 │\n",
      "│           ┆ new       ┆           ┆ 1         ┆   ┆ dding-3-s ┆ ID: 101   ┆ dding-3-s ┆ 7, 0.001 │\n",
      "│           ┆ product   ┆           ┆ 14:30:00  ┆   ┆ mall      ┆ provided  ┆ mall      ┆ 133, …   │\n",
      "│           ┆ line!     ┆           ┆           ┆   ┆           ┆ feedba…   ┆           ┆ -0.04226 │\n",
      "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 5…       │\n",
      "│ 102       ┆ The       ┆ [2, 3, 2] ┆ 2023-01-0 ┆ … ┆ text-embe ┆ Customer  ┆ text-embe ┆ [-0.0374 │\n",
      "│           ┆ service   ┆           ┆ 2         ┆   ┆ dding-3-s ┆ ID: 102   ┆ dding-3-s ┆ 93, 0.01 │\n",
      "│           ┆ was disap ┆           ┆ 09:15:00  ┆   ┆ mall      ┆ provided  ┆ mall      ┆ 3733, …  │\n",
      "│           ┆ pointing  ┆           ┆           ┆   ┆           ┆ feedba…   ┆           ┆ -0.03025 │\n",
      "│           ┆ th…       ┆           ┆           ┆   ┆           ┆           ┆           ┆ …        │\n",
      "│ 103       ┆ Great exp ┆ [5, 4, 5] ┆ 2023-01-0 ┆ … ┆ text-embe ┆ Customer  ┆ text-embe ┆ [-0.0192 │\n",
      "│           ┆ erience   ┆           ┆ 3         ┆   ┆ dding-3-s ┆ ID: 103   ┆ dding-3-s ┆ 91, -0.0 │\n",
      "│           ┆ with      ┆           ┆ 18:45:00  ┆   ┆ mall      ┆ provided  ┆ mall      ┆ 01914, … │\n",
      "│           ┆ customer  ┆           ┆           ┆   ┆           ┆ feedba…   ┆           ┆ -0.0262… │\n",
      "│           ┆ s…        ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "merged_df = merge_df_with_openai_emb_results(df_prompted, emb_payload_df, results_df, \"customer_prompt\")\n",
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Chat Completion API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cynde.functional.generate import generate_chat_completion_payloads, generate_chat_payloads_from_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"Evaluate the following customer feedback return a True or False based on the sentiment:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Pydantic Model inside None\n",
      "shape: (3, 2)\n",
      "┌───────────────────────────────────┬───────────────────────────────────┐\n",
      "│ customer_prompt                   ┆ str_messages                      │\n",
      "│ ---                               ┆ ---                               │\n",
      "│ str                               ┆ str                               │\n",
      "╞═══════════════════════════════════╪═══════════════════════════════════╡\n",
      "│ Customer ID: 101 provided feedba… ┆ {\"role\":\"system\",\"content\":\"Eval… │\n",
      "│ Customer ID: 102 provided feedba… ┆ {\"role\":\"system\",\"content\":\"Eval… │\n",
      "│ Customer ID: 103 provided feedba… ┆ {\"role\":\"system\",\"content\":\"Eval… │\n",
      "└───────────────────────────────────┴───────────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "payload_df = generate_chat_payloads_from_column(requests_filepath, df_prompted, \"customer_prompt\", system_prompt)\n",
    "print(payload_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nest_asyncio.apply()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cynde.functional.generate import process_and_merge_llm_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Starting request #0\n",
      "INFO:root:Starting request #1\n",
      "INFO:root:Starting request #2\n",
      "INFO:root:Parallel processing complete. Results saved to c:\\Users\\Tommaso\\Documents\\Dev\\Cynde\\cache\\openai_results.jsonl\n"
     ]
    }
   ],
   "source": [
    "request_url = \"https://api.openai.com/v1/chat/completions\"  # Replace with your actual API endpoint\n",
    "    # Process multiple api requests to ChatGPT\n",
    "asyncio.run(\n",
    "    process_api_requests_from_file(\n",
    "        requests_filepath=requests_filepath,\n",
    "        save_filepath=results_filepath,\n",
    "        request_url=request_url,\n",
    "        api_key=api_key,\n",
    "        max_requests_per_minute=float(90000),\n",
    "        max_tokens_per_minute=float(170000),\n",
    "        token_encoding_name=\"cl100k_base\",\n",
    "        max_attempts=int(5),\n",
    "        logging_level=int(20),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cynde.functional.generate import merge_df_with_openai_results,load_openai_results_jsonl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3, 5)\n",
      "┌─────────────────────┬─────────────────────┬───────────┬─────────────────────┬────────────────────┐\n",
      "│ messages            ┆ choices             ┆ usage     ┆ results             ┆ str_messages       │\n",
      "│ ---                 ┆ ---                 ┆ ---       ┆ ---                 ┆ ---                │\n",
      "│ list[struct[2]]     ┆ struct[2]           ┆ struct[3] ┆ struct[7]           ┆ str                │\n",
      "╞═════════════════════╪═════════════════════╪═══════════╪═════════════════════╪════════════════════╡\n",
      "│ [{\"system\",\"Evaluat ┆ {\"assistant\",\"False ┆ {80,1,81} ┆ {\"chatcmpl-8ohMf68J ┆ {\"role\":\"system\",\" │\n",
      "│ e the followi…      ┆ \"}                  ┆           ┆ VYbra9wxtdR4P…      ┆ content\":\"Eval…    │\n",
      "│ [{\"system\",\"Evaluat ┆ {\"assistant\",\"True\" ┆ {78,1,79} ┆ {\"chatcmpl-8ohMfqjH ┆ {\"role\":\"system\",\" │\n",
      "│ e the followi…      ┆ }                   ┆           ┆ JfCA8LIfCZuxc…      ┆ content\":\"Eval…    │\n",
      "│ [{\"system\",\"Evaluat ┆ {\"assistant\",\"True\" ┆ {79,1,80} ┆ {\"chatcmpl-8ohMgNc5 ┆ {\"role\":\"system\",\" │\n",
      "│ e the followi…      ┆ }                   ┆           ┆ eVHGEy8N7lZpz…      ┆ content\":\"Eval…    │\n",
      "└─────────────────────┴─────────────────────┴───────────┴─────────────────────┴────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "results_df = load_openai_results_jsonl(results_filepath)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3, 10)\n",
      "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
      "│ customer_ ┆ feedback  ┆ ratings   ┆ timestamp ┆ … ┆ messages  ┆ choices   ┆ usage     ┆ results  │\n",
      "│ id        ┆ ---       ┆ ---       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
      "│ ---       ┆ str       ┆ list[i64] ┆ datetime[ ┆   ┆ list[stru ┆ struct[2] ┆ struct[3] ┆ struct[7 │\n",
      "│ i64       ┆           ┆           ┆ μs]       ┆   ┆ ct[2]]    ┆           ┆           ┆ ]        │\n",
      "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
      "│ 101       ┆ Loved the ┆ [4, 5, 5] ┆ 2023-01-0 ┆ … ┆ [{\"system ┆ {\"assista ┆ {79,1,80} ┆ {\"chatcm │\n",
      "│           ┆ new       ┆           ┆ 1         ┆   ┆ \",\"Evalua ┆ nt\",\"True ┆           ┆ pl-8ohMg │\n",
      "│           ┆ product   ┆           ┆ 14:30:00  ┆   ┆ te the    ┆ \"}        ┆           ┆ Nc5eVHGE │\n",
      "│           ┆ line!     ┆           ┆           ┆   ┆ followi…  ┆           ┆           ┆ y8N7lZpz │\n",
      "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ …        │\n",
      "│ 102       ┆ The       ┆ [2, 3, 2] ┆ 2023-01-0 ┆ … ┆ [{\"system ┆ {\"assista ┆ {80,1,81} ┆ {\"chatcm │\n",
      "│           ┆ service   ┆           ┆ 2         ┆   ┆ \",\"Evalua ┆ nt\",\"Fals ┆           ┆ pl-8ohMf │\n",
      "│           ┆ was disap ┆           ┆ 09:15:00  ┆   ┆ te the    ┆ e\"}       ┆           ┆ 68JVYbra │\n",
      "│           ┆ pointing  ┆           ┆           ┆   ┆ followi…  ┆           ┆           ┆ 9wxtdR4P │\n",
      "│           ┆ th…       ┆           ┆           ┆   ┆           ┆           ┆           ┆ …        │\n",
      "│ 103       ┆ Great exp ┆ [5, 4, 5] ┆ 2023-01-0 ┆ … ┆ [{\"system ┆ {\"assista ┆ {78,1,79} ┆ {\"chatcm │\n",
      "│           ┆ erience   ┆           ┆ 3         ┆   ┆ \",\"Evalua ┆ nt\",\"True ┆           ┆ pl-8ohMf │\n",
      "│           ┆ with      ┆           ┆ 18:45:00  ┆   ┆ te the    ┆ \"}        ┆           ┆ qjHJfCA8 │\n",
      "│           ┆ customer  ┆           ┆           ┆   ┆ followi…  ┆           ┆           ┆ LIfCZuxc │\n",
      "│           ┆ s…        ┆           ┆           ┆   ┆           ┆           ┆           ┆ …        │\n",
      "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "merged_df = merge_df_with_openai_results(df_prompted, payload_df, results_df, \"customer_prompt\")\n",
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Starting request #0\n",
      "INFO:root:Starting request #1\n",
      "INFO:root:Starting request #2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating chat completion payloads...\n",
      "Using Pydantic Model before calling None\n",
      "Using Pydantic Model inside None\n",
      "Chat completion payloads generated in 0.00 seconds.\n",
      "Processing chat completion payloads with the LLM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Parallel processing complete. Results saved to c:\\Users\\Tommaso\\Documents\\Dev\\Cynde\\cache\\openai_results_.jsonl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat completion payloads processed in 0.53 seconds.\n",
      "Loading results from LLM processing...\n",
      "Results loaded in 0.01 seconds.\n",
      "Merging LLM results back into the original DataFrame...\n",
      "LLM results merged in 0.00 seconds.\n",
      "Total process completed in 0.54 seconds.\n",
      "shape: (3, 10)\n",
      "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
      "│ customer_ ┆ feedback  ┆ ratings   ┆ timestamp ┆ … ┆ messages  ┆ choices   ┆ usage     ┆ results  │\n",
      "│ id        ┆ ---       ┆ ---       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
      "│ ---       ┆ str       ┆ list[i64] ┆ datetime[ ┆   ┆ list[stru ┆ struct[2] ┆ struct[3] ┆ struct[7 │\n",
      "│ i64       ┆           ┆           ┆ μs]       ┆   ┆ ct[2]]    ┆           ┆           ┆ ]        │\n",
      "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
      "│ 101       ┆ Loved the ┆ [4, 5, 5] ┆ 2023-01-0 ┆ … ┆ [{\"system ┆ {\"assista ┆ {79,1,80} ┆ {\"chatcm │\n",
      "│           ┆ new       ┆           ┆ 1         ┆   ┆ \",\"Evalua ┆ nt\",\"True ┆           ┆ pl-8ohMg │\n",
      "│           ┆ product   ┆           ┆ 14:30:00  ┆   ┆ te the    ┆ \"}        ┆           ┆ YXJGFGcu │\n",
      "│           ┆ line!     ┆           ┆           ┆   ┆ followi…  ┆           ┆           ┆ 4OrB8tJ8 │\n",
      "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ …        │\n",
      "│ 102       ┆ The       ┆ [2, 3, 2] ┆ 2023-01-0 ┆ … ┆ [{\"system ┆ {\"assista ┆ {80,1,81} ┆ {\"chatcm │\n",
      "│           ┆ service   ┆           ┆ 2         ┆   ┆ \",\"Evalua ┆ nt\",\"Fals ┆           ┆ pl-8ohMg │\n",
      "│           ┆ was disap ┆           ┆ 09:15:00  ┆   ┆ te the    ┆ e\"}       ┆           ┆ oNKaMWdM │\n",
      "│           ┆ pointing  ┆           ┆           ┆   ┆ followi…  ┆           ┆           ┆ f8acBmbW │\n",
      "│           ┆ th…       ┆           ┆           ┆   ┆           ┆           ┆           ┆ …        │\n",
      "│ 103       ┆ Great exp ┆ [5, 4, 5] ┆ 2023-01-0 ┆ … ┆ [{\"system ┆ {\"assista ┆ {78,1,79} ┆ {\"chatcm │\n",
      "│           ┆ erience   ┆           ┆ 3         ┆   ┆ \",\"Evalua ┆ nt\",\"True ┆           ┆ pl-8ohMg │\n",
      "│           ┆ with      ┆           ┆ 18:45:00  ┆   ┆ te the    ┆ \"}        ┆           ┆ WjYgZZ2B │\n",
      "│           ┆ customer  ┆           ┆           ┆   ┆ followi…  ┆           ┆           ┆ rfPJdldk │\n",
      "│           ┆ s…        ┆           ┆           ┆   ┆           ┆           ┆           ┆ …        │\n",
      "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "merged_df = process_and_merge_llm_responses(df= df_prompted,\n",
    "                                column_name= \"customer_prompt\",\n",
    "                                system_prompt = system_prompt,\n",
    "                                requests_filepath = requests_filepath_,\n",
    "                                results_filepath = results_filepath_,\n",
    "                                api_key=api_key,)\n",
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from instructor.function_calls import openai_schema\n",
    "from pydantic import BaseModel, Field\n",
    "import enum\n",
    "from typing import Optional, List\n",
    "from cynde.utils.expressions import list_struct_to_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomerSentimentLabels(str, enum.Enum):\n",
    "    \"\"\"Enumeration for single-label customer sentiment classification.\"\"\"\n",
    "    POS = \"PositiveCustomerSentiment\"\n",
    "    NEG = \"NegativeCustomerSentiment\"\n",
    "\n",
    "class SentimentLabeller(BaseModel):\n",
    "    \"\"\"\n",
    "    Class for a single class label prediction.\n",
    "    \"\"\"\n",
    "    class_label: CustomerSentimentLabels\n",
    "    extra_details: Optional[str] = Field(None, description=\"Extra details used for the prediction.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Starting request #0\n",
      "INFO:root:Starting request #1\n",
      "INFO:root:Starting request #2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating chat completion payloads...\n",
      "Using Pydantic Model before calling <class '__main__.SentimentLabeller'>\n",
      "Using Pydantic Model inside <class '__main__.SentimentLabeller'>\n",
      "Using Pydantic Model\n",
      "Using Function Calling SentimentLabeller\n",
      "Chat completion payloads generated in 0.00 seconds.\n",
      "Processing chat completion payloads with the LLM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Parallel processing complete. Results saved to c:\\Users\\Tommaso\\Documents\\Dev\\Cynde\\cache\\openai_results_tools.jsonl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat completion payloads processed in 0.60 seconds.\n",
      "Loading results from LLM processing...\n",
      "Results loaded in 0.01 seconds.\n",
      "Merging LLM results back into the original DataFrame...\n",
      "LLM results merged in 0.00 seconds.\n",
      "Total process completed in 0.61 seconds.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (6,)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>choices</th></tr><tr><td>struct[3]</td></tr></thead><tbody><tr><td>{&quot;assistant&quot;,null,[{&quot;call_s4iKZka6P5AxzMDphu4oJpHa&quot;,&quot;function&quot;,{&quot;SentimentLabeller&quot;,&quot;{&quot;class_label&quot;:&quot;PositiveCustomerSentiment&quot;}&quot;}}]}</td></tr><tr><td>{&quot;assistant&quot;,null,[{&quot;call_xmbr4alXiv5WNqkR0fgu5uwo&quot;,&quot;function&quot;,{&quot;SentimentLabeller&quot;,&quot;{&quot;class_label&quot;:&quot;PositiveCustomerSentiment&quot;}&quot;}}]}</td></tr><tr><td>{&quot;assistant&quot;,null,[{&quot;call_AbVq7oJXx97ayU6xNruIpCnR&quot;,&quot;function&quot;,{&quot;SentimentLabeller&quot;,&quot;{&quot;class_label&quot;:&quot;NegativeCustomerSentiment&quot;}&quot;}}]}</td></tr><tr><td>{&quot;assistant&quot;,null,[{&quot;call_FUyXnrvlrWACvp3IHce5Nb7x&quot;,&quot;function&quot;,{&quot;SentimentLabeller&quot;,&quot;{&quot;class_label&quot;:&quot;NegativeCustomerSentiment&quot;}&quot;}}]}</td></tr><tr><td>{&quot;assistant&quot;,null,[{&quot;call_bP7y8aLMA7i8kgchpQDIGaCL&quot;,&quot;function&quot;,{&quot;SentimentLabeller&quot;,&quot;{&quot;class_label&quot;:&quot;PositiveCustomerSentiment&quot;}&quot;}}]}</td></tr><tr><td>{&quot;assistant&quot;,null,[{&quot;call_SCttvGUCIv7xDt0ed73oDS3X&quot;,&quot;function&quot;,{&quot;SentimentLabeller&quot;,&quot;{&quot;class_label&quot;:&quot;PositiveCustomerSentiment&quot;}&quot;}}]}</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (6,)\n",
       "Series: 'choices' [struct[3]]\n",
       "[\n",
       "\t{\"assistant\",null,[{\"call_s4iKZka6P5AxzMDphu4oJpHa\",\"function\",{\"SentimentLabeller\",\"{\"class_label\":\"PositiveCustomerSentiment\"}\"}}]}\n",
       "\t{\"assistant\",null,[{\"call_xmbr4alXiv5WNqkR0fgu5uwo\",\"function\",{\"SentimentLabeller\",\"{\"class_label\":\"PositiveCustomerSentiment\"}\"}}]}\n",
       "\t{\"assistant\",null,[{\"call_AbVq7oJXx97ayU6xNruIpCnR\",\"function\",{\"SentimentLabeller\",\"{\"class_label\":\"NegativeCustomerSentiment\"}\"}}]}\n",
       "\t{\"assistant\",null,[{\"call_FUyXnrvlrWACvp3IHce5Nb7x\",\"function\",{\"SentimentLabeller\",\"{\"class_label\":\"NegativeCustomerSentiment\"}\"}}]}\n",
       "\t{\"assistant\",null,[{\"call_bP7y8aLMA7i8kgchpQDIGaCL\",\"function\",{\"SentimentLabeller\",\"{\"class_label\":\"PositiveCustomerSentiment\"}\"}}]}\n",
       "\t{\"assistant\",null,[{\"call_SCttvGUCIv7xDt0ed73oDS3X\",\"function\",{\"SentimentLabeller\",\"{\"class_label\":\"PositiveCustomerSentiment\"}\"}}]}\n",
       "]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df_funct = process_and_merge_llm_responses(df= df_prompted,\n",
    "                                column_name= \"customer_prompt\",\n",
    "                                system_prompt = system_prompt,\n",
    "                                requests_filepath = requests_filepath_tools,\n",
    "                                results_filepath = results_filepath_tools,\n",
    "                                pydantic_model=SentimentLabeller,\n",
    "                                api_key=api_key,)\n",
    "merged_df_funct[\"choices\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = openai_schema(SentimentLabeller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_label=<CustomerSentimentLabels.POS: 'PositiveCustomerSentiment'> extra_details=None\n",
      "class_label=<CustomerSentimentLabels.POS: 'PositiveCustomerSentiment'> extra_details=None\n",
      "class_label=<CustomerSentimentLabels.NEG: 'NegativeCustomerSentiment'> extra_details=None\n"
     ]
    }
   ],
   "source": [
    "from cynde.functional.generate import load_openai_results_jsonl_pydantic\n",
    "from pydantic import ValidationError\n",
    "\n",
    "# Load and parse the file\n",
    "completions = load_openai_results_jsonl_pydantic(results_filepath_tools)\n",
    "pydantic_objects = []\n",
    "# Print or process the loaded completions as needed\n",
    "for completion in completions:\n",
    "    try:\n",
    "        out = schema.from_response(completion)\n",
    "        print(out)\n",
    "        pydantic_objects.append(out)\n",
    "    except ValidationError as e:\n",
    "        print(e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
